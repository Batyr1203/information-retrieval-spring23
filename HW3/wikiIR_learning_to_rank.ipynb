{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd1c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch    # elasticsearch will extract features from query-document pairs for us\n",
    "from elasticsearch.helpers import bulk, parallel_bulk\n",
    "from catboost import CatBoostRanker, Pool, MetricVisualizer\n",
    "from copy import deepcopy\n",
    "import ir_measures\n",
    "from ir_measures import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a9476",
   "metadata": {},
   "source": [
    "### Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44eecc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('http://localhost:9200')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997873a",
   "metadata": {},
   "source": [
    "### Index Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555a6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'wiki'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e412e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'wiki'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {\n",
    "    'properties': {\n",
    "        'text': {\n",
    "            'type': 'text',\n",
    "            'analyzer': 'white'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "settings = {\n",
    "    'analysis' : {\n",
    "        'analyzer' : {\n",
    "            'white' : {\n",
    "                'tokenizer' : 'whitespace'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, settings=settings, mappings=mappings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18a848",
   "metadata": {},
   "source": [
    "### WikiIR Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d270eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369721, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_right</th>\n",
       "      <th>text_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1781133</td>\n",
       "      <td>it was used in landing craft during world war ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2426736</td>\n",
       "      <td>after rejecting an offer from cambridge univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2224122</td>\n",
       "      <td>mat zan coached kuala lumpur fa in 1999 and wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219642</td>\n",
       "      <td>a barcode is a machine readable optical label ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1728654</td>\n",
       "      <td>since the subordination of the monarchy under ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_right                                         text_right\n",
       "0   1781133  it was used in landing craft during world war ...\n",
       "1   2426736  after rejecting an offer from cambridge univer...\n",
       "2   2224122  mat zan coached kuala lumpur fa in 1999 and wo...\n",
       "3    219642  a barcode is a machine readable optical label ...\n",
       "4   1728654  since the subordination of the monarchy under ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wikIR1k/documents.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3301cac",
   "metadata": {},
   "source": [
    "### Indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a151d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 369721/369721 [00:27<00:00, 13438.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing time: 27.649768114089966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': '1678134817', 'timestamp': '20:33:37', 'count': '369721'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }\n",
    "\n",
    "\n",
    "def es_action_generator(df):\n",
    "    for doc_id, row in tqdm(df.iterrows(), total=df.shape[0], bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}'):\n",
    "        doc = {\n",
    "            'text': row['text_right'],\n",
    "        }\n",
    "        yield create_es_action(index_name, row['id_right'], doc)\n",
    "\n",
    "\n",
    "start = time()\n",
    "for ok, result in parallel_bulk(es, es_action_generator(df), queue_size=4, thread_count=4, chunk_size=1000):\n",
    "    if not ok:\n",
    "        print(result)\n",
    "stop = time()\n",
    "\n",
    "print('Indexing time:', stop-start)\n",
    "        \n",
    "es.indices.refresh(index=index_name)\n",
    "es.cat.count(index=index_name, format='json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5741ca",
   "metadata": {},
   "source": [
    "### Train, Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2735e6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>text_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123839</td>\n",
       "      <td>yanni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188629</td>\n",
       "      <td>k pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13898</td>\n",
       "      <td>venice film festival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316959</td>\n",
       "      <td>downtown brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>515031</td>\n",
       "      <td>pennsylvania house of representatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>896124</td>\n",
       "      <td>british ceylon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>12319</td>\n",
       "      <td>scottish national party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>4421</td>\n",
       "      <td>cinema of china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>296526</td>\n",
       "      <td>gold mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>341793</td>\n",
       "      <td>gloucestershire county cricket club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_left                              text_left\n",
       "0      123839                                  yanni\n",
       "1      188629                                  k pop\n",
       "2       13898                   venice film festival\n",
       "3      316959                      downtown brooklyn\n",
       "4      515031  pennsylvania house of representatives\n",
       "...       ...                                    ...\n",
       "1439   896124                         british ceylon\n",
       "1440    12319                scottish national party\n",
       "1441     4421                        cinema of china\n",
       "1442   296526                            gold mining\n",
       "1443   341793    gloucestershire county cricket club\n",
       "\n",
       "[1444 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_queries = pd.read_csv('wikIR1k/training/queries.csv')\n",
    "train_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10de00cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>text_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158491</td>\n",
       "      <td>southern methodist university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5728</td>\n",
       "      <td>halakha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13554</td>\n",
       "      <td>chief justice of the united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32674</td>\n",
       "      <td>patsy cline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406391</td>\n",
       "      <td>dierks bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>679227</td>\n",
       "      <td>hiv aids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2136797</td>\n",
       "      <td>maren morris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5622</td>\n",
       "      <td>homer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1313598</td>\n",
       "      <td>south pole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>712704</td>\n",
       "      <td>west indies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_left                           text_left\n",
       "0    158491       southern methodist university\n",
       "1      5728                             halakha\n",
       "2     13554  chief justice of the united states\n",
       "3     32674                         patsy cline\n",
       "4    406391                      dierks bentley\n",
       "..      ...                                 ...\n",
       "95   679227                            hiv aids\n",
       "96  2136797                        maren morris\n",
       "97     5622                               homer\n",
       "98  1313598                          south pole\n",
       "99   712704                         west indies\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries = pd.read_csv('wikIR1k/test/queries.csv')\n",
    "test_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e27f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_result(search_result, fields=[]):\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits']:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "        for field in fields:\n",
    "            print(f'{field}: {hit[\"_source\"][field]}')\n",
    "    \n",
    "def search(query, *args):\n",
    "    return pretty_print_result(es.search(index=index_name, query=query, size=100), args)\n",
    "\n",
    "def get_doc_by_id(doc_id):\n",
    "    return es.get(index=index_name, id=doc_id)['_source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2346c496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 10000\n",
      "Doc 887826, score is 39.313705\n",
      "Doc 1176215, score is 37.12873\n",
      "Doc 1376470, score is 35.247803\n",
      "Doc 1569953, score is 34.36048\n",
      "Doc 1842084, score is 34.359726\n",
      "Doc 2369067, score is 33.912014\n",
      "Doc 1233841, score is 33.671608\n",
      "Doc 1382041, score is 33.65744\n",
      "Doc 832086, score is 33.563896\n",
      "Doc 1481340, score is 33.388405\n",
      "Doc 422337, score is 33.386597\n",
      "Doc 1315785, score is 33.376156\n",
      "Doc 1481358, score is 33.144707\n",
      "Doc 1481362, score is 33.026207\n",
      "Doc 1449050, score is 32.510365\n",
      "Doc 1125994, score is 31.858921\n",
      "Doc 1337630, score is 31.466238\n",
      "Doc 1376157, score is 31.149237\n",
      "Doc 888195, score is 30.324703\n",
      "Doc 854813, score is 29.80125\n",
      "Doc 843996, score is 29.800423\n",
      "Doc 837727, score is 29.799664\n",
      "Doc 843406, score is 29.19878\n",
      "Doc 1135269, score is 29.196968\n",
      "Doc 2223594, score is 28.857979\n",
      "Doc 836749, score is 28.844719\n",
      "Doc 1283126, score is 27.984835\n",
      "Doc 1275795, score is 27.766108\n",
      "Doc 823209, score is 27.725216\n",
      "Doc 2120091, score is 27.722628\n",
      "Doc 1453940, score is 27.695242\n",
      "Doc 730997, score is 27.122524\n",
      "Doc 837024, score is 27.021837\n",
      "Doc 1841970, score is 26.91972\n",
      "Doc 171754, score is 26.918713\n",
      "Doc 661710, score is 26.88544\n",
      "Doc 439742, score is 26.823082\n",
      "Doc 1282864, score is 26.569773\n",
      "Doc 1173097, score is 26.568745\n",
      "Doc 1183193, score is 26.30507\n",
      "Doc 1296073, score is 26.174767\n",
      "Doc 1241165, score is 26.174767\n",
      "Doc 705583, score is 26.15729\n",
      "Doc 366941, score is 26.112122\n",
      "Doc 685263, score is 26.053595\n",
      "Doc 1542377, score is 25.922962\n",
      "Doc 1345074, score is 25.922176\n",
      "Doc 1165681, score is 25.920929\n",
      "Doc 1805444, score is 25.74044\n",
      "Doc 243176, score is 25.572147\n",
      "Doc 1476533, score is 25.571812\n",
      "Doc 1212498, score is 25.571812\n",
      "Doc 1481183, score is 25.570824\n",
      "Doc 2172808, score is 25.568893\n",
      "Doc 2166633, score is 25.05806\n",
      "Doc 150129, score is 25.057058\n",
      "Doc 2086314, score is 25.05657\n",
      "Doc 2390192, score is 25.055809\n",
      "Doc 2342603, score is 25.054466\n",
      "Doc 1375172, score is 24.950363\n",
      "Doc 218327, score is 24.219809\n",
      "Doc 707195, score is 24.210108\n",
      "Doc 1372004, score is 23.62428\n",
      "Doc 754765, score is 22.901943\n",
      "Doc 1357456, score is 22.626228\n",
      "Doc 1562276, score is 22.625957\n",
      "Doc 720333, score is 21.783255\n",
      "Doc 837562, score is 21.543888\n",
      "Doc 91398, score is 20.58878\n",
      "Doc 828966, score is 20.090591\n",
      "Doc 694828, score is 19.955023\n",
      "Doc 842375, score is 19.659706\n",
      "Doc 1299663, score is 19.278751\n",
      "Doc 271705, score is 19.079607\n",
      "Doc 877538, score is 18.852797\n",
      "Doc 833635, score is 18.705582\n",
      "Doc 833613, score is 18.635693\n",
      "Doc 515031, score is 18.446558\n",
      "Doc 745251, score is 18.37906\n",
      "Doc 823332, score is 18.352097\n",
      "Doc 761490, score is 18.352097\n",
      "Doc 860147, score is 18.292519\n",
      "Doc 694904, score is 17.890923\n",
      "Doc 862679, score is 17.800232\n",
      "Doc 833668, score is 17.799824\n",
      "Doc 1003323, score is 17.653793\n",
      "Doc 825925, score is 17.637573\n",
      "Doc 443562, score is 17.531752\n",
      "Doc 737843, score is 17.289059\n",
      "Doc 842413, score is 17.288792\n",
      "Doc 828931, score is 17.287468\n",
      "Doc 739829, score is 17.252037\n",
      "Doc 707176, score is 17.206337\n",
      "Doc 1224853, score is 16.924776\n",
      "Doc 754830, score is 16.774044\n",
      "Doc 882599, score is 16.774044\n",
      "Doc 706420, score is 16.773483\n",
      "Doc 704724, score is 16.772453\n",
      "Doc 103607, score is 16.6025\n",
      "Doc 839112, score is 16.492176\n"
     ]
    }
   ],
   "source": [
    "def make_query(text):\n",
    "    return {\n",
    "        \"bool\": {\n",
    "            'must': {\n",
    "                'match': {\n",
    "                    'text': text\n",
    "                }                    \n",
    "            },\n",
    "            'should': {\n",
    "                \"match_phrase\": {\n",
    "                    \"text\": {\n",
    "                        \"query\": text,\n",
    "                        'slop': 10,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "search(make_query(train_queries['text_left'][4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ddf60",
   "metadata": {},
   "source": [
    "### Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76518df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(index_name, query_text, doc_id, verbose=False):\n",
    "    \n",
    "    # feature: query length\n",
    "    query_len = len(query_text.split(' '))\n",
    "    # feature: doc length\n",
    "    doc_len = len(get_doc_by_id(doc_id)['text'].split(' '))\n",
    "\n",
    "\n",
    "    # request with explain parameter\n",
    "    headers = {\n",
    "        'Content-type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "    json_data = {\n",
    "        'query': make_query(query_text)\n",
    "    }    \n",
    "    res = requests.get(f'http://127.0.0.1:9200/wiki/_explain/{doc_id}', headers=headers, json=json_data).json()\n",
    "\n",
    "    if verbose:\n",
    "        print(json.dumps(res, indent=2))\n",
    "    \n",
    "    total_score = 0\n",
    "    idfs = [0]\n",
    "    tfs = [0]\n",
    "    num_matched_terms = 0\n",
    "    phrase_freq = 0\n",
    "    phrase_match = 0\n",
    "    \n",
    "    if res['matched']:\n",
    "        # BM25 score\n",
    "        total_score = res['explanation']['value']\n",
    "        \n",
    "        terms_details = res['explanation']['details'][0]['details']\n",
    "        freqs = []\n",
    "        tfs = []\n",
    "        idfs = []\n",
    "        for term in terms_details:\n",
    "            if len(set(query_text.split(' ')))==1:\n",
    "                # features: terms' frequencies\n",
    "                m = re.search('freq=(\\d+)', term['description'])\n",
    "                freqs.append(int(m.group(1)))\n",
    "                # features: terms' idfs\n",
    "                idfs.append(term['details'][1]['value'])\n",
    "                # features: terms' tfs\n",
    "                tfs.append(term['details'][2]['value'])\n",
    "            else:\n",
    "                m = re.search('freq=(\\d+)', term['details'][0]['description'])\n",
    "                freqs.append(int(m.group(1)))\n",
    "                idfs.append(term['details'][0]['details'][1]['value'])\n",
    "                tfs.append(term['details'][0]['details'][2]['value'])\n",
    "            \n",
    "        num_matched_terms = np.count_nonzero(freqs)\n",
    "        \n",
    "        # if the response includes the second detail info, it means that the phrase matched as well\n",
    "        # (slop parameter might be included above, so phrase matches may not be strict)\n",
    "        if len(res['explanation']['details']) > 1:\n",
    "            phrase_details = res['explanation']['details'][1]\n",
    "            m = re.search('freq=(\\d+.\\d+)', phrase_details['details'][0]['description'])\n",
    "            phrase_freq = float(m.group(1))\n",
    "            phrase_match = 1 if float(m.group(1))>1 else 0\n",
    "\n",
    "\n",
    "    return {'bm25 score': total_score,\n",
    "            'query length': query_len,\n",
    "            'document length': doc_len,\n",
    "            '# of matched q/d terms': num_matched_terms,\n",
    "            'min idf': min(idfs),\n",
    "            'max idf': max(idfs),\n",
    "            'min tf': min(tfs),\n",
    "            'max tf': max(tfs),\n",
    "            'phrase frequency': phrase_freq\n",
    "#            'phrase match': phrase_match\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff598ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_index\": \"wiki\",\n",
      "  \"_id\": \"887826\",\n",
      "  \"matched\": true,\n",
      "  \"explanation\": {\n",
      "    \"value\": 39.313705,\n",
      "    \"description\": \"sum of:\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"value\": 20.014194,\n",
      "        \"description\": \"sum of:\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 7.7756023,\n",
      "            \"description\": \"weight(text:pennsylvania in 8063) [PerFieldSimilarity], result of:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 7.7756023,\n",
      "                \"description\": \"score(freq=6.0), computed as boost * idf * tf from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 2.2,\n",
      "                    \"description\": \"boost\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 4.247406,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 5287,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.83212304,\n",
      "                    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 6.0,\n",
      "                        \"description\": \"freq, occurrences of term within document\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 1.2,\n",
      "                        \"description\": \"k1, term saturation parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 0.75,\n",
      "                        \"description\": \"b, length normalization parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 200.0,\n",
      "                        \"description\": \"dl, length of field (approximate)\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 197.69969,\n",
      "                        \"description\": \"avgdl, average length of field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"value\": 4.7075586,\n",
      "            \"description\": \"weight(text:house in 8063) [PerFieldSimilarity], result of:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 4.7075586,\n",
      "                \"description\": \"score(freq=5.0), computed as boost * idf * tf from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 2.2,\n",
      "                    \"description\": \"boost\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2.6578329,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 25917,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.8050918,\n",
      "                    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 5.0,\n",
      "                        \"description\": \"freq, occurrences of term within document\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 1.2,\n",
      "                        \"description\": \"k1, term saturation parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 0.75,\n",
      "                        \"description\": \"b, length normalization parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 200.0,\n",
      "                        \"description\": \"dl, length of field (approximate)\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 197.69969,\n",
      "                        \"description\": \"avgdl, average length of field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"value\": 0.019180195,\n",
      "            \"description\": \"weight(text:of in 8063) [PerFieldSimilarity], result of:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 0.019180195,\n",
      "                \"description\": \"score(freq=14.0), computed as boost * idf * tf from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 2.2,\n",
      "                    \"description\": \"boost\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.009472072,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 366236,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.9204185,\n",
      "                    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 14.0,\n",
      "                        \"description\": \"freq, occurrences of term within document\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 1.2,\n",
      "                        \"description\": \"k1, term saturation parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 0.75,\n",
      "                        \"description\": \"b, length normalization parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 200.0,\n",
      "                        \"description\": \"dl, length of field (approximate)\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 197.69969,\n",
      "                        \"description\": \"avgdl, average length of field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"value\": 7.511853,\n",
      "            \"description\": \"weight(text:representatives in 8063) [PerFieldSimilarity], result of:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 7.511853,\n",
      "                \"description\": \"score(freq=4.0), computed as boost * idf * tf from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 2.2,\n",
      "                    \"description\": \"boost\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 4.4477615,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 4327,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.76768476,\n",
      "                    \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 4.0,\n",
      "                        \"description\": \"freq, occurrences of term within document\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 1.2,\n",
      "                        \"description\": \"k1, term saturation parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 0.75,\n",
      "                        \"description\": \"b, length normalization parameter\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 200.0,\n",
      "                        \"description\": \"dl, length of field (approximate)\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 197.69969,\n",
      "                        \"description\": \"avgdl, average length of field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"value\": 19.29951,\n",
      "        \"description\": \"weight(text:\\\"pennsylvania house of representatives\\\"~10 in 8063) [PerFieldSimilarity], result of:\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 19.29951,\n",
      "            \"description\": \"score(freq=4.1), computed as boost * idf * tf from:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 2.2,\n",
      "                \"description\": \"boost\",\n",
      "                \"details\": []\n",
      "              },\n",
      "              {\n",
      "                \"value\": 11.362473,\n",
      "                \"description\": \"idf, sum of:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 4.247406,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 5287,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2.6578329,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 25917,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.009472072,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 366236,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 4.4477615,\n",
      "                    \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                    \"details\": [\n",
      "                      {\n",
      "                        \"value\": 4327,\n",
      "                        \"description\": \"n, number of documents containing term\",\n",
      "                        \"details\": []\n",
      "                      },\n",
      "                      {\n",
      "                        \"value\": 369721,\n",
      "                        \"description\": \"N, total number of documents with field\",\n",
      "                        \"details\": []\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"value\": 0.77205944,\n",
      "                \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 4.1,\n",
      "                    \"description\": \"phraseFreq=4.1\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 1.2,\n",
      "                    \"description\": \"k1, term saturation parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.75,\n",
      "                    \"description\": \"b, length normalization parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 200.0,\n",
      "                    \"description\": \"dl, length of field (approximate)\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 197.69969,\n",
      "                    \"description\": \"avgdl, average length of field\",\n",
      "                    \"details\": []\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bm25 score': 39.313705,\n",
       " 'query length': 4,\n",
       " 'document length': 200,\n",
       " '# of matched q/d terms': 4,\n",
       " 'min idf': 0.009472072,\n",
       " 'max idf': 4.4477615,\n",
       " 'min tf': 0.76768476,\n",
       " 'max tf': 0.9204185,\n",
       " 'phrase frequency': 4.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the features extraction function\n",
    "extract_features(index_name='wiki',\n",
    "                 query_text=train_queries['text_left'][4],\n",
    "                 doc_id=887826,\n",
    "                 verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103d97a",
   "metadata": {},
   "source": [
    "## Costructing features dataframe\n",
    "\n",
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5b8bd",
   "metadata": {},
   "source": [
    "#### Reading relevant pairs (original set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5b8dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>val</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123839</td>\n",
       "      <td>0</td>\n",
       "      <td>123839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123839</td>\n",
       "      <td>0</td>\n",
       "      <td>1793430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123839</td>\n",
       "      <td>0</td>\n",
       "      <td>806300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123839</td>\n",
       "      <td>0</td>\n",
       "      <td>806075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123839</td>\n",
       "      <td>0</td>\n",
       "      <td>836567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47694</th>\n",
       "      <td>341793</td>\n",
       "      <td>0</td>\n",
       "      <td>1968690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47695</th>\n",
       "      <td>341793</td>\n",
       "      <td>0</td>\n",
       "      <td>1339149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47696</th>\n",
       "      <td>341793</td>\n",
       "      <td>0</td>\n",
       "      <td>1364202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47697</th>\n",
       "      <td>341793</td>\n",
       "      <td>0</td>\n",
       "      <td>1325652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47698</th>\n",
       "      <td>341793</td>\n",
       "      <td>0</td>\n",
       "      <td>1672870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47699 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         q_id  val   doc_id  relevance_label\n",
       "0      123839    0   123839                2\n",
       "1      123839    0  1793430                1\n",
       "2      123839    0   806300                1\n",
       "3      123839    0   806075                1\n",
       "4      123839    0   836567                1\n",
       "...       ...  ...      ...              ...\n",
       "47694  341793    0  1968690                1\n",
       "47695  341793    0  1339149                1\n",
       "47696  341793    0  1364202                1\n",
       "47697  341793    0  1325652                1\n",
       "47698  341793    0  1672870                1\n",
       "\n",
       "[47699 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relev_qd_pairs = pd.read_csv('wikIR1k/training/qrels', sep='\\t', header=None)\n",
    "train_relev_qd_pairs.columns = ['q_id', 'val', 'doc_id', 'relevance_label']\n",
    "train_relev_qd_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201a40f",
   "metadata": {},
   "source": [
    "#### Adding non-relevant pairs (extended set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9e9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1444/1444 [00:08<00:00, 173.30it/s]\n"
     ]
    }
   ],
   "source": [
    "q_ids = train_relev_qd_pairs['q_id'].unique()\n",
    "doc_ids = train_relev_qd_pairs['doc_id'].unique()\n",
    "\n",
    "for q_id in tqdm(q_ids, total=len(q_ids)):\n",
    "    add_doc_ids = random.sample(list(doc_ids), 10)\n",
    "    doc_ids_to_add = []\n",
    "    for doc_id in add_doc_ids:\n",
    "        if doc_id not in train_relev_qd_pairs.loc[train_relev_qd_pairs['q_id']==q_id, 'doc_id'].values:\n",
    "            doc_ids_to_add.append(doc_id)\n",
    "    new_qid_df = pd.DataFrame({'q_id': [q_id]*len(doc_ids_to_add),\n",
    "                               'val': [0]*len(doc_ids_to_add),\n",
    "                               'doc_id': doc_ids_to_add,\n",
    "                               'relevance_label': [0]*len(doc_ids_to_add)})\n",
    "    train_relev_qd_pairs = pd.concat([train_relev_qd_pairs, new_qid_df]).sort_values(by=['q_id']).reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3ae53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>val</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2415640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2193064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>731995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1886924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2393413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62124</th>\n",
       "      <td>2433785</td>\n",
       "      <td>0</td>\n",
       "      <td>2433061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62125</th>\n",
       "      <td>2433785</td>\n",
       "      <td>0</td>\n",
       "      <td>730722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62126</th>\n",
       "      <td>2433785</td>\n",
       "      <td>0</td>\n",
       "      <td>2279766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62127</th>\n",
       "      <td>2433785</td>\n",
       "      <td>0</td>\n",
       "      <td>68013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62128</th>\n",
       "      <td>2433785</td>\n",
       "      <td>0</td>\n",
       "      <td>730108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id  val   doc_id  relevance_label\n",
       "0           79    0  2415640                1\n",
       "1           79    0  2193064                0\n",
       "2           79    0   731995                0\n",
       "3           79    0  1886924                0\n",
       "4           79    0  2393413                0\n",
       "...        ...  ...      ...              ...\n",
       "62124  2433785    0  2433061                1\n",
       "62125  2433785    0   730722                1\n",
       "62126  2433785    0  2279766                0\n",
       "62127  2433785    0    68013                0\n",
       "62128  2433785    0   730108                1\n",
       "\n",
       "[62129 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relev_qd_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155b97b",
   "metadata": {},
   "source": [
    "#### Features dataframe (feature extraction applied on extended dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd391400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 62129/62129 [05:32<00:00, 186.66it/s]      \n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "for i, row in tqdm(train_relev_qd_pairs.iterrows(), total=train_relev_qd_pairs.shape[0], bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}'):\n",
    "    query_text = train_queries.loc[train_queries['id_left']==row['q_id'], 'text_left'].item()\n",
    "    curr_features = {\n",
    "        'relevance': row['relevance_label'],\n",
    "        'queryid': row['q_id'],\n",
    "    }\n",
    "    curr_features.update(extract_features(index_name='wiki', query_text=query_text, doc_id=row['doc_id']))\n",
    "    pairs.append(curr_features)\n",
    "\n",
    "train_df = pd.DataFrame(pairs)\n",
    "train_df.to_csv('train_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89ffbc84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>queryid</th>\n",
       "      <th>bm25 score</th>\n",
       "      <th>query length</th>\n",
       "      <th>document length</th>\n",
       "      <th># of matched q/d terms</th>\n",
       "      <th>min idf</th>\n",
       "      <th>max idf</th>\n",
       "      <th>min tf</th>\n",
       "      <th>max tf</th>\n",
       "      <th>phrase frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9030</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.936617</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9034</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9035</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>1.475154</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.712509</td>\n",
       "      <td>0.712509</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9036</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9037</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9038</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.936617</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>0</td>\n",
       "      <td>4332</td>\n",
       "      <td>2.000579</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.010102</td>\n",
       "      <td>2.010102</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>2</td>\n",
       "      <td>4332</td>\n",
       "      <td>27.876028</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.941075</td>\n",
       "      <td>4.890121</td>\n",
       "      <td>0.805092</td>\n",
       "      <td>0.900866</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>10.867170</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9048</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>14.964513</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>0.622961</td>\n",
       "      <td>0.622961</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9049</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9050</th>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>10.867170</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>5.459449</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      relevance  queryid  bm25 score  query length  document length  \\\n",
       "9030          1     4332    0.000000             3              186   \n",
       "9031          0     4332    0.000000             3              200   \n",
       "9032          0     4332    0.936617             3              200   \n",
       "9033          1     4332    0.000000             3              200   \n",
       "9034          0     4332    0.000000             3              200   \n",
       "9035          0     4332    1.475154             3              200   \n",
       "9036          0     4332    0.000000             3              200   \n",
       "9037          1     4332    0.000000             3              200   \n",
       "9038          1     4332    0.936617             3              200   \n",
       "9039          1     4332    0.000000             3              200   \n",
       "9040          1     4332    0.000000             3              188   \n",
       "9041          0     4332    2.000579             3              200   \n",
       "9042          1     4332    0.000000             3              200   \n",
       "9043          2     4332   27.876028             3              200   \n",
       "9044          1     4332    0.000000             3              200   \n",
       "9045          1     4334    0.000000             1              189   \n",
       "9046          1     4334   10.867170             1              200   \n",
       "9047          1     4334    0.000000             1              198   \n",
       "9048          1     4334   14.964513             1              200   \n",
       "9049          1     4334    0.000000             1              200   \n",
       "9050          1     4334   10.867170             1              200   \n",
       "\n",
       "      # of matched q/d terms   min idf   max idf    min tf    max tf  \\\n",
       "9030                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9031                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9032                       1  0.941075  0.941075  0.452392  0.452392   \n",
       "9033                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9034                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9035                       1  0.941075  0.941075  0.712509  0.712509   \n",
       "9036                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9037                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9038                       1  0.941075  0.941075  0.452392  0.452392   \n",
       "9039                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9040                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9041                       1  2.010102  2.010102  0.452392  0.452392   \n",
       "9042                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9043                       3  0.941075  4.890121  0.805092  0.900866   \n",
       "9044                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9045                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9046                       1  5.459449  5.459449  0.452392  0.452392   \n",
       "9047                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9048                       1  5.459449  5.459449  0.622961  0.622961   \n",
       "9049                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "9050                       1  5.459449  5.459449  0.452392  0.452392   \n",
       "\n",
       "      phrase frequency  \n",
       "9030          0.000000  \n",
       "9031          0.000000  \n",
       "9032          0.000000  \n",
       "9033          0.000000  \n",
       "9034          0.000000  \n",
       "9035          0.000000  \n",
       "9036          0.000000  \n",
       "9037          0.000000  \n",
       "9038          0.000000  \n",
       "9039          0.000000  \n",
       "9040          0.000000  \n",
       "9041          0.000000  \n",
       "9042          0.000000  \n",
       "9043          4.285714  \n",
       "9044          0.000000  \n",
       "9045          0.000000  \n",
       "9046          1.000000  \n",
       "9047          0.000000  \n",
       "9048          2.000000  \n",
       "9049          0.000000  \n",
       "9050          1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[9030:9050,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8db20",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d808d6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>val</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158491</td>\n",
       "      <td>0</td>\n",
       "      <td>158491</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158491</td>\n",
       "      <td>0</td>\n",
       "      <td>2130828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158491</td>\n",
       "      <td>0</td>\n",
       "      <td>730939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158491</td>\n",
       "      <td>0</td>\n",
       "      <td>1666627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158491</td>\n",
       "      <td>0</td>\n",
       "      <td>2102124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>712704</td>\n",
       "      <td>0</td>\n",
       "      <td>591264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>712704</td>\n",
       "      <td>0</td>\n",
       "      <td>908363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>712704</td>\n",
       "      <td>0</td>\n",
       "      <td>2004825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>712704</td>\n",
       "      <td>0</td>\n",
       "      <td>307988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>712704</td>\n",
       "      <td>0</td>\n",
       "      <td>1577576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4435 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q_id  val   doc_id  relevance_label\n",
       "0     158491    0   158491                2\n",
       "1     158491    0  2130828                1\n",
       "2     158491    0   730939                1\n",
       "3     158491    0  1666627                1\n",
       "4     158491    0  2102124                1\n",
       "...      ...  ...      ...              ...\n",
       "4430  712704    0   591264                1\n",
       "4431  712704    0   908363                1\n",
       "4432  712704    0  2004825                1\n",
       "4433  712704    0   307988                1\n",
       "4434  712704    0  1577576                1\n",
       "\n",
       "[4435 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relev_qd_pairs = pd.read_csv('wikIR1k/test/qrels', sep='\\t', header=None)\n",
    "test_relev_qd_pairs.columns = ['q_id', 'val', 'doc_id', 'relevance_label']\n",
    "test_relev_qd_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3929c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 480.62it/s]\n"
     ]
    }
   ],
   "source": [
    "q_ids = test_relev_qd_pairs['q_id'].unique()\n",
    "doc_ids = test_relev_qd_pairs['doc_id'].unique()\n",
    "\n",
    "for q_id in tqdm(q_ids, total=len(q_ids)):\n",
    "    add_doc_ids = random.sample(list(doc_ids), 10)\n",
    "    doc_ids_to_add = []\n",
    "    for doc_id in add_doc_ids:\n",
    "        if doc_id not in test_relev_qd_pairs.loc[test_relev_qd_pairs['q_id']==q_id, 'doc_id'].values:\n",
    "            doc_ids_to_add.append(doc_id)\n",
    "    new_qid_df = pd.DataFrame({'q_id': [q_id]*len(doc_ids_to_add),\n",
    "                               'val': [0]*len(doc_ids_to_add),\n",
    "                               'doc_id': doc_ids_to_add,\n",
    "                               'relevance_label': [0]*len(doc_ids_to_add)})\n",
    "    test_relev_qd_pairs = pd.concat([test_relev_qd_pairs, new_qid_df]).sort_values(by=['q_id']).reset_index(drop=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebce5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 5427/5427 [00:28<00:00, 188.62it/s]        \n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "for i, row in tqdm(test_relev_qd_pairs.iterrows(), total=test_relev_qd_pairs.shape[0], bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}'):\n",
    "    query_text = test_queries.loc[test_queries['id_left']==row['q_id'], 'text_left'].item()\n",
    "    curr_features = {\n",
    "        'relevance': row['relevance_label'],\n",
    "        'queryid': row['q_id'],\n",
    "    }\n",
    "    curr_features.update(extract_features(index_name='wiki', query_text=query_text, doc_id=row['doc_id']))\n",
    "    pairs.append(curr_features)\n",
    "\n",
    "test_df = pd.DataFrame(pairs)\n",
    "test_df.to_csv('test_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9239bcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>queryid</th>\n",
       "      <th>bm25 score</th>\n",
       "      <th>query length</th>\n",
       "      <th>document length</th>\n",
       "      <th># of matched q/d terms</th>\n",
       "      <th>min idf</th>\n",
       "      <th>max idf</th>\n",
       "      <th>min tf</th>\n",
       "      <th>max tf</th>\n",
       "      <th>phrase frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>10.585438</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>7.723694</td>\n",
       "      <td>7.723694</td>\n",
       "      <td>0.622961</td>\n",
       "      <td>0.622961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>1</td>\n",
       "      <td>2136797</td>\n",
       "      <td>5.552353</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>5.578782</td>\n",
       "      <td>5.578782</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.452392</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>0</td>\n",
       "      <td>2136797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>0</td>\n",
       "      <td>2136797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>1</td>\n",
       "      <td>2136797</td>\n",
       "      <td>9.881150</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>5.578782</td>\n",
       "      <td>5.578782</td>\n",
       "      <td>0.805092</td>\n",
       "      <td>0.805092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>0</td>\n",
       "      <td>2136797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      relevance  queryid  bm25 score  query length  document length  \\\n",
       "0             1      720    0.000000             2              200   \n",
       "1             1      720    0.000000             2              200   \n",
       "2             2      720   10.585438             2              200   \n",
       "3             1      720    0.000000             2              200   \n",
       "4             1      720    0.000000             2              200   \n",
       "...         ...      ...         ...           ...              ...   \n",
       "5422          1  2136797    5.552353             2              200   \n",
       "5423          0  2136797    0.000000             2              200   \n",
       "5424          0  2136797    0.000000             2              200   \n",
       "5425          1  2136797    9.881150             2              200   \n",
       "5426          0  2136797    0.000000             2              200   \n",
       "\n",
       "      # of matched q/d terms   min idf   max idf    min tf    max tf  \\\n",
       "0                          0  0.000000  0.000000  0.000000  0.000000   \n",
       "1                          0  0.000000  0.000000  0.000000  0.000000   \n",
       "2                          1  7.723694  7.723694  0.622961  0.622961   \n",
       "3                          0  0.000000  0.000000  0.000000  0.000000   \n",
       "4                          0  0.000000  0.000000  0.000000  0.000000   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "5422                       1  5.578782  5.578782  0.452392  0.452392   \n",
       "5423                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "5424                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "5425                       1  5.578782  5.578782  0.805092  0.805092   \n",
       "5426                       0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      phrase frequency  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "5422               0.0  \n",
       "5423               0.0  \n",
       "5424               0.0  \n",
       "5425               0.0  \n",
       "5426               0.0  \n",
       "\n",
       "[5427 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952170ee",
   "metadata": {},
   "source": [
    "## ML with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14404b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 0].values\n",
    "queries_train = train_df.iloc[:, 1].values\n",
    "\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_test = test_df.iloc[:, 0].values\n",
    "queries_test = test_df.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae365083",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4b3afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train documents: 62129\n",
      "Number of test documents: 5427\n",
      "Number of train queries (number of train query groups): 1444\n",
      "Number of test queries (number of test query groups): 100\n",
      "Number of features: 9\n"
     ]
    }
   ],
   "source": [
    "train_num_documents = X_train.shape[0]\n",
    "print('Number of train documents:', train_num_documents)\n",
    "\n",
    "test_num_documents = X_test.shape[0]\n",
    "print('Number of test documents:', test_num_documents)\n",
    "\n",
    "# print('Distribution of relevance scores:')\n",
    "# Counter(y_train).items()\n",
    "\n",
    "# Normalization of relevance scores\n",
    "max_relevance = np.max(y_train)\n",
    "y_train = np.float64(y_train) / max_relevance\n",
    "y_test = np.float64(y_test) / max_relevance\n",
    "\n",
    "train_num_queries = np.unique(queries_train).shape[0]\n",
    "print('Number of train queries (number of train query groups):', train_num_queries)\n",
    "\n",
    "test_num_queries = np.unique(queries_test).shape[0]\n",
    "print('Number of test queries (number of test query groups):', test_num_queries)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "print('Number of features:', num_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3e196",
   "metadata": {},
   "source": [
    "### Creation of CatBoost pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a6047ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=queries_train\n",
    ")\n",
    "\n",
    "test = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_id=queries_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec747be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {\n",
    "    'iterations': 2000,\n",
    "    'custom_metric': ['NDCG'],\n",
    "    'verbose': False,\n",
    "    'random_seed': 0,\n",
    "}\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "def fit_model(loss_function, additional_params=None, train_pool=train, test_pool=test):\n",
    "    parameters = deepcopy(default_parameters)\n",
    "    parameters['loss_function'] = loss_function\n",
    "    parameters['train_dir'] = loss_function\n",
    "    \n",
    "    if additional_params is not None:\n",
    "        parameters.update(additional_params)\n",
    "        \n",
    "    model = CatBoostRanker(**parameters)\n",
    "    model.fit(train_pool, eval_set=test_pool, plot=True)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a4f2",
   "metadata": {},
   "source": [
    "### 1st Variant: PairLogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdbca121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27402ddb6e144da9811d6f66fd43e53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair_logit_model = fit_model('PairLogit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eab1ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best iteration: 434\n",
      "{\n",
      "    \"learn\": {\n",
      "        \"PairLogit\": 0.2764341571462773\n",
      "    },\n",
      "    \"validation\": {\n",
      "        \"NDCG:type=Base\": 0.9229695158201754,\n",
      "        \"PairLogit\": 0.3584478230199964\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('best iteration:', pair_logit_model.best_iteration_)\n",
    "print(json.dumps(pair_logit_model.best_score_, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0942b",
   "metadata": {},
   "source": [
    "### 2nd Variant: YetiRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc035c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11b29e8293e4a6f9bdf67ae01bf28cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yeti_rank_model = fit_model('YetiRank')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
